% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lm2.R
\name{lm2}
\alias{lm2}
\title{Enhanced Linear Regression (lm)}
\usage{
lm2(
  formula,
  data = NULL,
  se_type = "HC3",
  output = "statuser",
  notes = TRUE,
  ...
)
}
\arguments{
\item{formula}{An object of class \code{\link{formula}}: a symbolic description
of the model to be fitted.}

\item{data}{A data frame containing the variables in the model.}

\item{se_type}{The type of standard error to use. Default is \code{"HC3"}.
See \code{\link[estimatr]{lm_robust}} for options.}

\item{output}{Character string specifying output format. \code{"statuser"} (default)
returns an enhanced table with standardized coefficients and both robust and
classical standard errors. \code{"estimatr"} returns the standard
\code{lm_robust} output.}

\item{notes}{Logical. If TRUE (default), print explanatory notes below the table
when the result is printed.}

\item{...}{Additional arguments passed to \code{\link[estimatr]{lm_robust}}.}
}
\value{
When \code{output = "estimatr"}, returns an object of class \code{lm_robust}.
  When \code{output = "statuser"}, returns a data frame with the following columns:
  \itemize{
    \item \code{term}: The predictor name
    \item \code{estimate}: The coefficient estimate
    \item \code{SE.robust}: Robust standard error (using \code{se_type})
    \item \code{SE.classical}: Classical (OLS) standard error
    \item \code{t}: t-statistic (based on robust SE)
    \item \code{df}: Degrees of freedom
    \item \code{p.value}: p-value (based on robust SE)
    \item \code{B}: Standardized coefficient (beta)
    \item \code{red.flag}: Diagnostic flags (see Details)
  }
}
\description{
Runs a linear regression with better defaults (robust SE), and richer & better 
formatted output than \code{lm}. For robust and clustered errors it relies on \code{\link[estimatr]{lm_robust}}. 
The output reports classical and robust errors, number of missing observations per
variable, an effect size column (standardized regression coefficient), and a red.flag column per variable 
flagging the need to conduct specific diagnostics. It relies by default on HC3 for standard errors;
\code{lm_robust} relies on HC2 (and Stata's 'reg y x, robust' on HC1), which can have
inflated false-positive rates in smaller samples (Long & Ervin, 2000).
}
\details{
The \code{red.flag} column provides diagnostic warnings:
\itemize{
  \item \code{!}, \code{!!}, \code{!!!}: Robust and classical standard errors differ by 
    more than 25\%, 50\%, or 100\%, respectively. Large differences may suggest model 
    misspecification or outliers (but they may also be benign). When encountering a red flag,
    authors should plot the distributions to look for outliers or skewed data, and use scatter.gam()
    to look for possible nonlinearities in the relevant variables.
    King & Roberts (2015) propose a higher cutoff, at 100\%, and a bootstrapped significance test; 
    \code{statuser} does not follow either recommendation. The former seems too liberal, the 
    latter too time consuming to include in every regression.
  \item \code{X} and \code{X*}: For interaction terms, the component variables are correlated with 
    |r| > 0.3 (\code{X}) or p < .05 (\code{X*}); this can produce spurious interactions. Authors are advised
    to not rely on the linear model and instead use GAM (Simonsohn, 2024).
}
}
\examples{
# Basic usage with data argument
lm2(mpg ~ wt + hp, data = mtcars)

# Without data argument (variables from environment)
y <- mtcars$mpg
x1 <- mtcars$wt
x2 <- mtcars$hp
lm2(y ~ x1 + x2)

# RED FLAG EXAMPLES

# Example 1: red flag catches a nonlinearity
# True model is quadratic: y = x^2
set.seed(123)
x <- runif(200, -3, 3)
y <- x^2 + rnorm(200, sd = 2)

# lm2() shows red flag due to misspecification
lm2(y ~ x)

# Follow up with scatter.gam() to diagnose it
scatter.gam(x, y)

# Example 2: red flag catches an outlier in y
# True model is y = x, but one observation has a very large y value
set.seed(123)
x <- sort(rnorm(200))
y <- round(x + rnorm(200, sd = 2), 1)
y[200] <- 100  # Outlier

# lm2() flags x
lm2(y ~ x)

# Look at distribution of y to spot the outlier
plot_freq(y)

# Example 3: red flag catches an outlier in one predictor
# True model is y = x1 + x2, but x2 has an extreme value
set.seed(123)
x1 <- rnorm(200)
x2 <- rnorm(200)
y <- x1 + x2 + rnorm(200, sd = 0.5)
x2[200] <- 50  # Outlier in x2

# lm2() flags x2 (but not x1)
lm2(y ~ x1 + x2)

# Look at distribution of x2 to spot the outlier
plot_freq(x2)

}
\references{
King, G., & Roberts, M. E. (2015). How robust standard errors expose methodological 
problems they do not fix, and what to do about it. \emph{Political Analysis}, 23(2), 159-179.

Long, J. S., & Ervin, L. H. (2000). Using heteroscedasticity consistent standard errors 
in the linear regression model. \emph{The American Statistician}, 54(3), 217-224.

Simonsohn, U. (2024). Interacting with curves: How to validly test and probe 
interactions in the real (nonlinear) world. \emph{Advances in Methods and Practices in 
Psychological Science}, 7(1), 1-22.
}
\seealso{
\code{\link[estimatr]{lm_robust}}, \code{\link{scatter.gam}}
}
